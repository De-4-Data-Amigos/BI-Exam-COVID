{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Intelligence exam project march 2024\n",
    "Group members: Rasmus Arendt, Deniz Denson, Victor Christensen & Marcus Løbel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean the data\n",
    "\n",
    "### We engineer & wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data. The data is from the Our World in Data's github (https://github.com/owid/covid-19-data/tree/master/public/data). downloaded on 10/03/2024\n",
    "df = pd.read_csv(\"./Data/owid-covid-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the data is loaded correctly\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the columns to see what we have, and later decide what to use\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For our three hypothesis', we will use the following columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep_hypo1 = ['iso_code','location', 'total_cases', 'gdp_per_capita','date']\n",
    "columns_to_keep_hypo2 = ['iso_code', 'location', 'total_cases', 'date', 'total_vaccinations_per_hundred', 'population_density']\n",
    "columns_to_keep_hypo3 = ['stringency_index', 'human_development_index' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe with the columns we've chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df\n",
    "data_hypo1 = df[columns_to_keep_hypo1]\n",
    "data_hypo2 = df[columns_to_keep_hypo2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data to see if it looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a sample\n",
    "print(data_hypo1.sample(5))\n",
    "print(data_hypo2.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the percentage of missing values in data_hypo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get percentage of missing values\n",
    "missing_values = (data_hypo1.isnull().sum()/data_hypo1.shape[0])*100\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the rows with missing values in the total_cases column, because we can't get that data from anywhere else and then check the missing values again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows\n",
    "data_hypo1 = data_hypo1.dropna(subset=['total_cases'])\n",
    "data_hypo2 = data_hypo2.dropna(subset=['total_cases'])\n",
    "\n",
    "missing_values_hypo1 = (data_hypo1.isnull().sum()/data_hypo1.shape[0])*100\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the date column into a datetime object, as that's more useful for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date column -> datetime\n",
    "data_hypo1['date'] = pd.to_datetime(data_hypo1['date'])\n",
    "data_hypo2['date'] = pd.to_datetime(data_hypo2['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get a list of the iso codes, to see what countries we have data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the iso codes\n",
    "iso_codes_hypo1 = data_hypo1['iso_code'].unique()\n",
    "iso_codes_hypo1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of owid special codes (which are not countries!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# owid special codes\n",
    "iso_codes_owid = data_hypo1[data_hypo1['iso_code'].str.contains('OWID')]['iso_code'].unique()\n",
    "iso_codes_owid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the owid rows from the data, because we are only interested in actual countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows\n",
    "data_hypo1 = data_hypo1[~data_hypo1['iso_code'].str.contains('OWID')]\n",
    "data_hypo2 = data_hypo2[~data_hypo2['iso_code'].str.contains('OWID')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data to make sure all the owid rows are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if it's done correct\n",
    "iso_codes_owid = data_hypo1[data_hypo1['iso_code'].str.contains('OWID')]['iso_code'].unique()\n",
    "iso_codes_owid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then find any countries that doesnt have any data in the population_density column.\n",
    "\n",
    "Note: We use the iso code, because it is unique for each country, and other data might have different names for the same country or capital letters for a country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_population_density = data_hypo2[data_hypo2['population_density'].isnull()]['iso_code'].unique()\n",
    "missing_population_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load another dataset so we can fill some of the missing data in the population density column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "pop_density = pd.read_csv(\"./Data/population-density.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then find the first year present in the covid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year = data_hypo2['date'].min().year\n",
    "first_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the last year in the covid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_year = data_hypo2['date'].max().year\n",
    "last_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. because we can then remove rows that are not within the range of the first and last year of the covid dataset, because we only need data from inside the covid-period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#discard unusuable years\n",
    "pop_density = pop_density[pop_density['Year'] >= first_year]\n",
    "pop_density = pop_density[pop_density['Year'] <= last_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data to see its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if it looks good :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the percentage of missing values in the pop_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pop_density.isnull().sum()/pop_density.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which rows has missing values in the Code column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density[pop_density['Code'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then remove rows with missing values in the Code column, as they are not useful for our analysis, as they are not associated with any country, but rather a region, continent or group of people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density = pop_density.dropna(subset=['Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then re-check the percentage of missing values, to make sure the rows are correctly removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pop_density.isnull().sum()/pop_density.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the amount of countries in the population density dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pop_density['Entity'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the population density column to make it easier to work with, when we merge the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pop_density.rename(columns={'Entity':'location', 'Code':'iso_code','Year':'year', 'Population density': 'population_density'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns to see if the renaming was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if done correct\n",
    "pop_density.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out if the countries in the covid dataset, with missing population_density, are in the population density dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover if it exists\n",
    "doesnt_exists = []\n",
    "for code in missing_population_density:\n",
    "    if not code in pop_density['iso_code'].unique():\n",
    "        doesnt_exists.append(code)\n",
    "\n",
    "print(len(doesnt_exists), len(missing_population_density))\n",
    "print(doesnt_exists)\n",
    "# this means that there is 5 countries in the covid dataset, with missing population_density, that are not in the population density dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the countries that are not in the population density dataset from the covid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove excess countries that are not there\n",
    "data_hypo2 = data_hypo2[~data_hypo2['iso_code'].isin(doesnt_exists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypo2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will fill in the missing population density data, by using the population density dataset and a new dataframe as an intermediary dataframe\n",
    "\n",
    "### This is done by finding the population density data for the countries with missing population density, and then putting this data into a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_missing_pop_density = data_hypo2[data_hypo2['population_density'].isnull()]\n",
    "df_with_pop_filled = pd.DataFrame(columns=data_hypo2.columns)\n",
    "for row in rows_with_missing_pop_density.iterrows():\n",
    "    index = row[0]\n",
    "    row = row[1]\n",
    "    year = row['date'].year\n",
    "    location = row['location']\n",
    "    iso_code = row['iso_code']\n",
    "    year_condition = pop_density['year'] == year\n",
    "    iso_code_condition = pop_density['iso_code'] == iso_code\n",
    "    combined_condition = year_condition & iso_code_condition\n",
    "    pop_density_row = pop_density[combined_condition]\n",
    "    #print(row)\n",
    "    df_with_pop_filled.loc[index] = [iso_code, location, row['total_cases'], pop_density_row['population_density'].values[0], row['date'], row['total_vaccinations_per_hundred']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the data from the intermediary dataframe into the original covid dataframe at the correct index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data from intermediary df to original df\n",
    "data_hypo2['population_density'] = data_hypo2['population_density'].fillna(df_with_pop_filled['population_density'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the rows with missing values in the gdp_per_capita column, because we can't get that data from anywhere else that is up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with missing values in gdp_per_capital column\n",
    "data_hypo1 = data_hypo1.dropna(subset=['gdp_per_capita'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with missing values in population_density\n",
    "data_hypo2 = data_hypo2.dropna(subset=['population_density'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_hypo2.isnull().sum()/data_hypo2.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load another dataset to so we can fill some of the missing data in the total_vaccinations_per_hundred column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load another dataset to fill data\n",
    "vacc_per_hundred_dataset = pd.read_csv(\"./Data/covid-vaccination-doses-per-capita.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_per_hundred_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_per_hundred_dataset.rename(columns={'Entity':'location', 'Code':'iso_code','Day':'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_per_hundred_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_missing_vacc_per_hundred = data_hypo2[data_hypo2['total_vaccinations_per_hundred'].isnull()]\n",
    "print(f\"covid data is missing {len(rows_with_missing_vacc_per_hundred)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of missing values\n",
    "missing_values = (data_hypo2.isnull().sum()/data_hypo2.shape[0])*100\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypo2['date'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_per_hundred_dataset['date'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_per_hundred_dataset['date'] = pd.to_datetime(vacc_per_hundred_dataset['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vacc_merge_datasets(dataset1, dataset2):\n",
    "    # Convert dates to datetime objects\n",
    "    dataset1['date'] = pd.to_datetime(dataset1['date'])\n",
    "    dataset2['date'] = pd.to_datetime(dataset2['date'])\n",
    "\n",
    "    # Merge datasets based on 'iso_code' and 'date'\n",
    "    merged = pd.merge(dataset1, dataset2, on=['iso_code', 'date'], how='left', suffixes=('_1', '_2'))\n",
    "\n",
    "    # Replace missing values in 'total_vaccinations_per_hundred_1' with values from 'total_vaccinations_per_hundred_2'\n",
    "    merged['total_vaccinations_per_hundred'] = merged['total_vaccinations_per_hundred_1'].fillna(merged['total_vaccinations_per_hundred_2'])\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    merged.drop(['total_vaccinations_per_hundred_1', 'total_vaccinations_per_hundred_2'], axis=1, inplace=True)\n",
    "\n",
    "    # Fill missing values in 'total_vaccinations_per_hundred' with most recent values from dataset2\n",
    "    merged['total_vaccinations_per_hundred'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = fill_missing_vaccination_data(data_hypo2, vacc_per_hundred_dataset)\n",
    "intermediary_dataset = vacc_merge_datasets(data_hypo2, vacc_per_hundred_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediary_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the data from the intermediary dataframe into the original covid dataframe at the correct index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypo2['total_vaccinations_per_hundred'] = data_hypo2['total_vaccinations_per_hundred'].fillna(intermediary_dataset['total_vaccinations_per_hundred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the rows with missing values in the total_vaccinations_per_hundred column, because we can't get that data from anywhere else and check the missing values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_hypo2 = data_hypo2.dropna(subset=['total_vaccinations_per_hundred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypo2.isnull().sum()/data_hypo2.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1\n",
    "\n",
    "### \"We do not believe that there is a correlation between the number of infected individuals in relation to a country's Gross National Product (GNP) per capita.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the covid data to use for hypothesis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data\n",
    "data_hypothesis_1 = data_hypo1[['location', 'total_cases', 'gdp_per_capita', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypothesis_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the last row for each countries latest observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_row = data_hypothesis_1.groupby('location').last().reset_index()\n",
    "last_row.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the last row for each country has the same date, so the data fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_row['date'].max() == last_row['date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a subset of the data to use for the graph, where it is sorted by the total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of the cumulative cases per country\n",
    "data_hypothesis_1_subset = last_row.sort_values('total_cases', ascending=False)\n",
    "plt.figure(figsize=(200,100))\n",
    "sns.barplot(x='location', y='total_cases', data=data_hypothesis_1_subset)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot to show gdp_per_capita as x and total_cases for each country as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='gdp_per_capita', y='total_cases', data=last_row)\n",
    "plt.title('Total cases vs GDP per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the each country's BNP per capita and the number of infected people in the country. We can also see that there is 3 outliers in the data. These are (China), (USA) and (Italy). We will remove these from the data to get a better overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypo1['date'] = pd.to_datetime(data_hypo1['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = data_hypo1['date'].dt.year.unique()\n",
    "years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piechart to show  the top 5 countries with the highest average total cases for each year that we have data for as a single graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i, y in enumerate(years, start=1):\n",
    "    plt.subplot(3, 2, i)\n",
    "     # get the avg total cases per country for the year\n",
    "    avg_total_cases = data_hypo1[data_hypo1['date'].dt.year == y].groupby('location')['total_cases'].mean()\n",
    "    avg_total_cases = avg_total_cases.reset_index()\n",
    "    avg_total_cases = avg_total_cases.sort_values(by='total_cases', ascending=False)\n",
    "    # get the top 5 countries\n",
    "    top_5 = avg_total_cases.head(5)\n",
    "    plt.pie(top_5['total_cases'], labels=top_5['location'], autopct='%.1f%%',\n",
    "            startangle=90, shadow=True)\n",
    "    plt.title(y, fontsize=15)\n",
    "\n",
    "plt.suptitle('Top 5 highest average total cases per country foreach year', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 2\n",
    "\n",
    "### \"We believe there is a connection between a country's population density and the number of COVID-19 cases, where higher population density correlates with more COVID-19 cases. That is to say, countries with more cases also had higher vaccination coverage.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the necessary columns to the hypothesis 2 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy columns\n",
    "data_hypothesis_2 = data_hypo2[['location', 'total_cases', 'total_vaccinations_per_hundred']]\n",
    "\n",
    "\n",
    "# Check the data to see if it looks good\n",
    "print(data_hypothesis_2.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypothesis_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with missing values in the 'total_cases' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypothesis_2.dropna(subset=['total_cases'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hypothesis_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the last row for each countries latest observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_row = data_hypothesis_2.groupby('location').last().reset_index()\n",
    "last_row.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot to show how vaccines per hundred people per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Sort the data by 'total_vaccinations_per_hundred' column\n",
    "data_hypothesis_2_subset = data_hypothesis_2.sort_values('total_vaccinations_per_hundred', ascending=False)\n",
    "\n",
    "# Create a bar plot with plotly\n",
    "fig = px.bar(data_hypothesis_2_subset, x='location', y='total_vaccinations_per_hundred',\n",
    "             labels={'total_vaccinations_per_hundred': 'Total Vaccinations per Hundred'},\n",
    "             title='Total Vaccinations per Hundred by Country')\n",
    "\n",
    "# Add hover data to show country names\n",
    "fig.update_traces(hovertemplate='<b>%{x}</b><br>Total Vaccinations per Hundred: %{y}')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot to show how vaccines per hundred people per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a scatter plot with plotly\n",
    "fig = px.scatter(data_hypothesis_2_subset, x='total_cases', y='total_vaccinations_per_hundred', hover_name='location',\n",
    "                 labels={'total_cases': 'Total COVID-19 Cases', 'total_vaccinations_per_hundred': 'Vaccinations per Hundred'},\n",
    "                 title='Relationship between COVID-19 Cases and Vaccination Coverage')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 5 countries with the highest average number of cases for vaccination coverage per hundred\n",
    "top_5_countries = data_hypothesis_2_subset.groupby('location')['total_vaccinations_per_hundred'].mean().nlargest(5).index\n",
    "\n",
    "# Create a subset of data containing only the top 5 countries\n",
    "top_5_data = data_hypothesis_2_subset[data_hypothesis_2_subset['location'].isin(top_5_countries)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='location', y='total_vaccinations_per_hundred', data=top_5_data, order=top_5_countries)\n",
    "plt.title('Top 5 lande med det højeste gennemsnitlige antal sager for vaccinationsdækning per hundrede')\n",
    "plt.xlabel('Land')\n",
    "plt.ylabel('Gennemsnitlig vaccinationsdækning per hundrede')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotese 3\n",
    "\n",
    "### \"We do not believe all countries are equally exposed to infection\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
